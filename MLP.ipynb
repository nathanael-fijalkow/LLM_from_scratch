{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aee500dc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# LLM from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ab15cf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The goal is to code from scratch (using Pytorch) a Transformer, more precisely a GPT-like model (using a decoder-only architecture)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ef709fb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a081d49",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64 # number of sequences processed in parallel\n",
    "n_token = 512 # number of tokens (used for the tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f4014a",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Part 1: Playing with the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf30164",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Let's download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1a95e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"huggingartists/bob-dylan\", split=\"train\")\n",
    "ds = ds.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c54411bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 2016\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 225\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "707cd887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'They say everything can be replaced\\nYet every distance is not near\\nSo I remember every face\\nOf every man who put me here\\nI see my light come shining\\nFrom the west unto the east\\nAny day now, any day now\\nI shall be released\\nThey say every man needs protection\\nThey say every man must fall\\nYet I swear I see my reflection\\nSome place so high above this wall\\nI see my light come shining\\nFrom the west unto the east\\nAny day now, any day now\\nI shall be released\\nStanding next to me in this lonely crowd\\nIs a man who swears hes not to blame\\nAll day long I hear him shout so loud\\nCrying out that he was framed\\nI see my light come shining\\nFrom the west unto the east\\nAny day now, any day now\\nI shall be released'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b07d0c7",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Part 2: Word-level tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efdc19e",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The science of decomposing a text into tokens is a complicated one. Here we use `minbpe`, which implements the Byte Pair Encoding (BPE) algorithm commonly used in LLM tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d47e963c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from minbpe.minbpe import RegexTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ffbf657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'re\\nIve been walking that lonesome valley\\nJust tryin to get to heaven before they close the door\\nPe'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_text = \"\\n\".join(ds[\"train\"][x][\"text\"] for x in range(20))\n",
    "partial_text[502:600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d9fe3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexTokenizer()\n",
    "tokenizer.train(partial_text, 512, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be0494d",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We encode the entire text datasets and store them into `torch.Tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01141736",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1238679]),\n",
       " tensor([330, 261, 480, 408, 359, 116, 276, 319, 300, 409,  10, 330, 447, 261,\n",
       "         297, 117, 418, 419, 322, 267, 260, 107, 105, 304,  10,  73, 280, 385,\n",
       "         331, 100, 276, 329, 114, 502, 267, 319, 308, 265, 117, 100, 100, 121,\n",
       "         331, 409,  10,  87, 351, 267, 295, 342]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = \"\\n\".join(ds[\"train\"][x][\"text\"] for x in range(ds[\"train\"].num_rows))\n",
    "val_data = \"\\n\".join(ds[\"test\"][x][\"text\"] for x in range(ds[\"test\"].num_rows))\n",
    "\n",
    "train_data = torch.tensor(tokenizer.encode(train_data), dtype=torch.long)\n",
    "val_data = torch.tensor(tokenizer.encode(val_data), dtype=torch.long)\n",
    "\n",
    "train_data.shape, train_data[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f52b388",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([257, 273, 111, 369, 317], ['he', 'll', 'o', ' wor', 'ld'], 'hello world')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"hello world\"\n",
    "test_encoded = tokenizer.encode(test)\n",
    "test_encoded, [tokenizer.decode([x]) for x in test_encoded], tokenizer.decode(test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de89dcdf",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The longest tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a1edc56",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' lonesome',\n",
       " ' tonight',\n",
       " 'onesome',\n",
       " ' heaven',\n",
       " ' gonna',\n",
       " ' right',\n",
       " ' broke',\n",
       " ' every',\n",
       " ' worry',\n",
       " ' heave',\n",
       " 'arling',\n",
       " ' that',\n",
       " ' your',\n",
       " ' with',\n",
       " ' hard',\n",
       " ' baby',\n",
       " ' Lord',\n",
       " ' dont',\n",
       " ' want',\n",
       " ' been']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_list = sorted([tokenizer.decode([x]) for x in range(n_token)], \n",
    "                    key=len, \n",
    "                    reverse=True)\n",
    "token_list[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b0c72f",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Part 3: Evaluating and training with batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a4c5514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736d4a2c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Our models will take as input `context_length` many tokens and produce the next token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c5030cb",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  [114, 424, 10, 80, 310, 97, 315, 44, 465, 114, 115, 46, 32, 72, 312, 311, 44, 465, 114, 115, 46, 32, 72, 312, 311, 44, 306, 310, 97, 315, 10, 80, 310, 97, 315, 44, 465, 114, 115, 46, 32, 72, 312, 311, 44, 465, 114, 115, 46, 32, 72, 312, 311, 44, 306, 310, 97, 315, 10, 73, 109, 442, 301, 302] \n",
      "Target:  422\n",
      "\n",
      "Human version:\n",
      "Input:  rake\n",
      "Please, Mrs. Henry, Mrs. Henry, please\n",
      "Please, Mrs. Henry, Mrs. Henry, please\n",
      "Im down on my \n",
      "Target:   kn\n"
     ]
    }
   ],
   "source": [
    "context_length_test = 64\n",
    "\n",
    "ix = torch.randint(len(train_data) - context_length_test, (1,))\n",
    "sample = train_data[ix:ix+context_length_test+1]\n",
    "sample_list = sample.tolist()\n",
    "print(\"Input: \", sample_list[:-1], \n",
    "      \"\\nTarget: \", sample_list[-1])\n",
    "print(\"\\nHuman version:\\nInput: \", tokenizer.decode(sample_list[:-1]), \n",
    "      \"\\nTarget: \", tokenizer.decode([sample_list[-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b230feed",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 8]), torch.Size([64, 8]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_batch(split, context_length):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - context_length - 1, (batch_size,))\n",
    "    X = torch.stack([data[i:i+context_length] for i in ix])\n",
    "    Y = torch.stack([data[i+1:i+context_length+1] for i in ix])\n",
    "    return X, Y\n",
    "\n",
    "X,Y = get_batch(\"train\", 8)\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eae7678",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We illustrate below how the cross entropy loss is computed along batches (as the mean over the batches). The same works for most functions in Pytorch, which means that writing code for batches is almost as easy as without!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a97afb12",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits:  tensor([[ 0.1251,  0.5692,  1.3950,  1.1641,  0.3252],\n",
      "        [-1.7733, -0.5491, -0.5605,  0.2494, -1.7450],\n",
      "        [ 2.8234,  1.2044,  1.8606,  0.0484,  2.3630]]) \n",
      "target:  tensor([4, 0, 1]) \n",
      "loss:  2.451202869415283\n"
     ]
    }
   ],
   "source": [
    "batch_size_test = 3\n",
    "number_classes_test = 5\n",
    "\n",
    "logits = torch.randn(batch_size_test, number_classes_test)\n",
    "target = torch.randint(number_classes_test, (batch_size_test,), dtype=torch.int64)\n",
    "loss = F.cross_entropy(logits, target)\n",
    "print(\"logits: \", logits, \"\\ntarget: \", target, \"\\nloss: \", loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5821f7ed",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Let us write the boilerplate code for models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86666e05",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def estimate_loss(model, eval_iters):\n",
    "    out = {}\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split, model.context_length)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "548f60c9",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, n_iterations, learning_rate, eval_interval, eval_iters):\n",
    "    # create a PyTorch optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for iter in range(n_iterations):\n",
    "        # every once in a while evaluate the loss on train and validation sets\n",
    "        if iter % eval_interval == 0 or iter == n_iterations - 1:\n",
    "            with torch.no_grad():\n",
    "                losses = estimate_loss(model, eval_iters)\n",
    "            print(f\"step {iter}: train loss {losses['train']:.4f}, validation loss {losses['val']:.4f}\")\n",
    "\n",
    "        X,Y = get_batch(\"train\", model.context_length)\n",
    "        X.to(device)\n",
    "        Y.to(device)\n",
    "        _, loss = model(X, Y)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6763e6",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Part 4: A Multi Layer Perceptron (MLP) model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf539672",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We essentially implement the model from the paper \"**A Neural Probabilistic Language Model**\" by Bengio et al from 2003.\n",
    "\n",
    "The first component is an `Embedding` layer: this is simply a lookup table, as illustrated below. It maps every token to a vector in fixed dimension. Since the dimension is much smaller than the number of tokens, intuitively the embedding layer will have to map similar tokens to similar vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0845733",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of the embedding:\n",
      " Parameter containing:\n",
      "tensor([[ 0.6620,  1.2090,  1.1550,  0.7025],\n",
      "        [-1.4797, -0.8685,  1.0905,  0.0762],\n",
      "        [-0.4418,  0.0631,  0.0292, -1.0604]], requires_grad=True)\n",
      "Result of embedding token number 1:\n",
      " tensor([[-1.4797, -0.8685,  1.0905,  0.0762]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "n_token_test = 3\n",
    "n_embed_test = 4\n",
    "\n",
    "embedding = torch.nn.Embedding(n_token_test, n_embed_test)\n",
    "print(\"Weights of the embedding:\\n\", embedding.weight)\n",
    "print(\"Result of embedding token number 1:\\n\", embedding(torch.tensor([1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180d5752",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Let us describe how the model works. \n",
    "\n",
    "Recall that a datapoint is a tensor `x` of size `context_length`. Each of the `context_length` token is embedded, yielding a tensor of dimension `n_embed`. The resulting embeddings are concatenated to form a tensor of dimension `context_length * n_embed`, and then fed into a standard feed forward network. This is illustrated below (minus the network), with batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c5d7dd4",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tokens:\n",
      " tensor([[0, 0, 1],\n",
      "        [2, 3, 1]])\n",
      "Weights of the embedding:\n",
      " Parameter containing:\n",
      "tensor([[-1.1578, -1.6146,  0.6327, -0.4978, -0.4117],\n",
      "        [-0.1228, -0.9923, -0.2605,  0.6617, -0.3110],\n",
      "        [-0.4971,  1.0045, -0.7694, -1.7252,  0.6582],\n",
      "        [-0.6170,  0.0245,  1.2861,  0.9131,  1.1492],\n",
      "        [ 1.3680, -0.6166,  0.3669,  0.3993,  2.0496]], requires_grad=True)\n",
      "*******************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 5]),\n",
       " tensor([[[-1.1578, -1.6146,  0.6327, -0.4978, -0.4117],\n",
       "          [-1.1578, -1.6146,  0.6327, -0.4978, -0.4117],\n",
       "          [-0.1228, -0.9923, -0.2605,  0.6617, -0.3110]],\n",
       " \n",
       "         [[-0.4971,  1.0045, -0.7694, -1.7252,  0.6582],\n",
       "          [-0.6170,  0.0245,  1.2861,  0.9131,  1.1492],\n",
       "          [-0.1228, -0.9923, -0.2605,  0.6617, -0.3110]]],\n",
       "        grad_fn=<EmbeddingBackward0>))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size_test = 2\n",
    "context_length_test = 3\n",
    "n_token_test = 4\n",
    "n_embed_test = 5\n",
    "\n",
    "blank_token_test = n_token_test\n",
    "\n",
    "idx = torch.randint(high = n_token_test, size = (batch_size_test, context_length_test))\n",
    "print(\"Input tokens:\\n\", idx)\n",
    "embedding = torch.nn.Embedding(n_token_test + 1, n_embed_test)\n",
    "print(\"Weights of the embedding:\\n\", embedding.weight)\n",
    "\n",
    "print(\"*******************\\n\")\n",
    "\n",
    "x = embedding(idx)\n",
    "x.shape, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2831e1fa",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 context_length = 32,\n",
    "                 n_embed = 64, \n",
    "                 n_hidden = 512):\n",
    "        super().__init__()\n",
    "        self.context_length = context_length\n",
    "        self.n_embed = n_embed\n",
    "        self.n_hidden = n_hidden\n",
    "        self.model_type = \"MLP\"\n",
    "        self.token_embedding_table = nn.Embedding(n_token, n_embed)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(context_length * n_embed, n_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hidden, n_token)\n",
    "        )\n",
    "\n",
    "    def forward(self, idx, y=None):\n",
    "        B, T = idx.shape\n",
    "        # if training: B = batch_size, otherwise B = 1\n",
    "        # T = context_length\n",
    "\n",
    "        x = self.token_embedding_table(idx).view(B, -1)\n",
    "        # x.shape = (B, T * n_embed)\n",
    "        \n",
    "        logits = self.net(x) \n",
    "        # logits.shape = (B, n_token)\n",
    "        \n",
    "        if y is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # y.shape = (B, T)\n",
    "            logits = logits.view(B, -1)\n",
    "            # we only consider the last token for prediction\n",
    "            y = y[:,-1].view(B)\n",
    "            loss = F.cross_entropy(logits, y)\n",
    "        return logits, loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83235d51",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.344512  M parameters\n"
     ]
    }
   ],
   "source": [
    "model = MLP(context_length = 32,\n",
    "            n_embed = 64, \n",
    "            n_hidden = 512)\n",
    "model.to(device)\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, ' M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78a3c4b3",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def generate(model, context_length, max_new_tokens = 2000, topk = 5):\n",
    "    idx = torch.ones((1, context_length), dtype=torch.long) * tokenizer.encode(\"\\n\")[0]\n",
    "    idx.to(device)\n",
    "    for _ in range(max_new_tokens):\n",
    "        # we crop at context_length\n",
    "        idx_cond = idx[:, -context_length:]\n",
    "        # forward pass\n",
    "        logits, _ = model(idx_cond)\n",
    "        \n",
    "        # for MLP:\n",
    "        # logits.shape = (batch_size, context_length, n_token)\n",
    "        # for Transformers:\n",
    "        # logits.shape = (batch_size, n_token)\n",
    "        if model.type == \"sliding windows\":\n",
    "            logits = logits[:,-1,:]\n",
    "\n",
    "        # topk\n",
    "        v, _ = torch.topk(logits, topk)\n",
    "        logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "\n",
    "        # apply softmax to convert logits to (normalized) probabilities\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        # sample from the distribution\n",
    "        idx_next = torch.multinomial(probs, num_samples=1).view((1,1))\n",
    "        # append sampled index to the running sequence and continue\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return tokenizer.decode(idx[0][context_length:].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09956f5c",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B��ryin me:imGBSB:ryin:imNow: mele:�=�Bim�d wahatNndnyndqΏ4 had&�ad l(3But�V@�j\n"
     ]
    }
   ],
   "source": [
    "print(generate(model, model.context_length, max_new_tokens = 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "214d556f",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 6.2815, validation loss 6.2749\n",
      "step 1000: train loss 4.0349, validation loss 4.1508\n",
      "step 2000: train loss 3.6604, validation loss 3.8464\n",
      "step 3000: train loss 3.4801, validation loss 3.7293\n",
      "step 4000: train loss 3.3946, validation loss 3.6793\n",
      "step 5000: train loss 3.2864, validation loss 3.5923\n",
      "step 6000: train loss 3.2060, validation loss 3.6118\n",
      "step 7000: train loss 3.1557, validation loss 3.4880\n",
      "step 8000: train loss 3.0884, validation loss 3.4130\n",
      "step 9000: train loss 3.0442, validation loss 3.4620\n",
      "step 9999: train loss 2.9619, validation loss 3.3815\n"
     ]
    }
   ],
   "source": [
    "train(model, \n",
    "      n_iterations = 10000,\n",
    "      learning_rate = 1e-3,\n",
    "      eval_interval = 1000,\n",
    "      eval_iters = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8906962b",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rong you you you\n",
      "\n",
      "m\n",
      "\n",
      "r you\n",
      "It you tale\n",
      "\n",
      "Youre you\n",
      "It you are come und\n",
      "Yourre ass you\n",
      "You wonna love me\n",
      "Mr one\n",
      "It compens\n",
      "It you sheping a big\n",
      "Fiers were burwice orr\n",
      "You couldnt take me to be soeras\n",
      "When they deace in the cartigs swell\n",
      "To make your mades quarp\n",
      "Mever ato cartctor\n",
      "The cants and the wice\n",
      "Loo, swier there aint\n",
      "Nocongooo will\n",
      "You know gonna have no dongers soon\n",
      "G\n"
     ]
    }
   ],
   "source": [
    "print(generate(model, model.context_length, max_new_tokens = 200))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
